\section{Introduction}

%\begin{itemize}
%	\item Motivation: Why load balancing
%	\item Context: Scenarios in which global rescheduling applies
%	\item Problem: Scaling iterative applications: algorithm limitations
%	\item Justification: Scalable load balancing, distributed rescheduling
%	\item Related work: Hierarchical (limited scaling), Distributed (excessive comm), Diffusive (iterative), Refinement Based (centralized)
%	\item Proposed solution: Batch task migration to mitigate communication costs
%	\item Paper contributions	
%	\item Results brief
%	\item Paper structure
%\end{itemize}

%Growth of systems and applications.
%Need to achieve high scalability to use platforms.
%Efficient scheduling and use of resources.
%
%Dynamic iterative applications.
%Unable to use work stealing.
%Global rescheduling as a solution.
%
%Strong scaling of applications.
%Cost of centralized load balancing.
%Using platform parallelism to achive performance.
%Communication costs as a relevant overhead.
%
%Present hierarchical LB.
%Pros: weak scaling, topology.
%Cons: high comms, bottlenecks.
%Present distributed LB.
%Pros: parallel, refinement.
%Cons: high comms, network contention.
%
%\textbf{Cut out topo aware and diffusive, not related enough.}
%
%Brief intro to BTM.
%Reduced communication.
%Highly parallel.
%Fast convergence.
%
%Present contributions.
%
%Brief results.
%
%Present paper structure.
%
%\hline

Parallel machines are at their best when work is evenly distributed among compute nodes, and idle time is merely a myth.
Unfortunately, strong scaling applications for these platforms has been a challenge as long as they have existed.
Uneven distribution of work and high communication overheads are the main villains when devoloping parallel applications~\cite{Deveci2015, commaware}.
Concern towards these problems increases as system grow in size, consuming more power and resources to solve problems.

Applications such as simulations of molecular dynamics (MD) and hydrodynamics suffer from load imbalance due to their intrinsic dynamic and iterative nature~\cite{namd,IPDPS13:LULESH}.
Although rescheduling algorithms have been able to greatly improve applications~\cite{namd0}, new approaches are needed to guarantee their performance as parallel systems grow.
Since mapping work to processing elements (PEs) is a NP-Hard problem~\cite{npcomplete}, the increase in application data and platform size makes centralized approaches to rescheduling innefficient.
This creates a need for scalable, decentralized, rescheduling approaches, avoiding both excess of data to process and network contention~\cite{trahay2009scalable}.

The two main paths to achieve scalable global rescheduling in the iterative application domain are Hierarchical and Distributed approaches.
Hierarchical load balancing explores parallelism using different approaches for fine-grain and coarse-grain steps~\cite{hybrid}.
These can scale, but are usually tied to the same limitations as the Centralized, as data is still agregated in master nodes.
On the other hand, Distributed load balancing seeks to achieve scalability in a decentralized fashion.
These scale better, but have limited system information and may incur in high amounts of communication.

Few are the Distributed strategies in the domain of global rescheduling, but their effectiviness is notable~\cite{grapevine,diffus}.
In this paper, we present the concept of \textit{Batch Task Migration} and a novel distributed global rescheduling algorithm that applies this technique, \textit{PackDrop}.
Our approach is based on the idea of grouping tasks prior to migration decisions in batches, decreasing communication overhead in algorithm decision time and enhancing locality of migrated tasks.

% Main contributions
In this paper, we present the following contributions: 
\begin{enumerate}
	\item A \textit{Batch Task Migration} approach for distributed rescheduling algorithms, which presents high scalability and task affinity potential.
	\item A novel distributed rescheduling algorithm, using our \textit{Batch Task Migration} approach, \textit{PackDrop}.
	\item An implementation of our algorithm, as well as a performance evaluation of this implementation.
\end{enumerate}

The remainder of this paper is divided as follows:
Section~\ref{sec:rw} presents recent work in dynamic rescheduling of scientific applications. 
Section~\ref{sec:algo} presents our novel approach and the developed algorithms. 
Section~\ref{sec:analysis} is a complexity analysis of \textit{PackDrop}, our distributed algorithm. 
Section~\ref{sec:impl} displays implementation details, execution environments and benchmarks used in this paper. 
Section~\ref{sec:eval} displays our performance evaluation and discussed experiments. 
And Section~\ref{sec:conclusion} presents the conclusion of this work and our plans for future research.


