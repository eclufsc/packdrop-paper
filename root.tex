%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%2345678901234567890123456789012345678901234567890123456789012345678901234567890
%        1         2         3         4         5         6         7         8

\documentclass[a4paper, 10pt, twocolumn, final]{article}  % Comment this line out if you need a4paper

%\documentclass[a4paper, 10pt, conference]{ieeeconf}      % Use this line for a4 paper

%\IEEEoverridecommandlockouts                              % This command is only needed if
                                                          % you want to use the \thanks command


% See the \addtolength command later in the file to balance the column lengths
% on the last page of the document

% The following packages can be found on http:\\www.ctan.org
\usepackage{graphics} % for pdf, bitmapped graphics files
\usepackage{epsfig} % for postscript graphics files
\usepackage{mathptmx} % assumes new font selection scheme installed
\usepackage{times} % assumes new font selection scheme installed
\usepackage[utf8]{inputenc}
\usepackage[onelanguage,linesnumbered, boxruled]{algorithm2e}
\usepackage{booktabs} % For formal tables
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{lipsum}
\usepackage{todonotes}
\usepackage{xcolor}
\usepackage{subfigure}
\usepackage{multirow}

\hyphenation{cen-tra-li-zed}

\newcommand{\packdrop}{$PackDrop$\xspace}
\newcommand{\batchsend}{$BatchSend$\xspace}
\newcommand{\batchassembly}{$BatchAssembly$\xspace}
\providecommand{\keywords}[1]{\textbf{\textit{Index terms---}} #1}
\newcommand{\distributedlb}{$Distributed$\xspace}
\newcommand{\dummylb}{$Dummy$\xspace}
\newcommand{\greedylb}{$Greedy$\xspace}
\newcommand{\refinelb}{$Refine$\xspace}
\newcommand{\charm}{{\small\texttt{Charm++}}\xspace}

\newcommand\tofix[1]{\textcolor{orange}{#1}}

\title{A Batch Task Migration Approach for Decentralized Global Rescheduling}

% Organizar as linhas de autores de forma diferente. Está muito caótico com múltiplas pessoas da mesma instituição as vezes separadas e as vezes juntas

\author{
Vinicius Freitas\thanks{Vinicius Freitas is with the Embedded Computing Lab (ECL) and with the Distributed Systems Research Lab (LaPeSD) at the Federal University of Santa Catarina (UFSC) --- Florianópolis, Brazil.  Contact information: {\footnotesize \tt vinicius.mct.freitas@gmail.com}} , Alexandre de L. Santana\thanks{Alexandre de L. Santana is with ECL at UFSC --- Florianópolis, Brazil.} , Márcio Castro\thanks{Márcio Castro is with LaPeSD at UFSC --- Florianópolis, Brazil. Contact information: {\footnotesize \tt marcio.castro@ufsc.br}} , Laércio L. Pilla\thanks{Laércio is with the Univ. Grenoble Alpes, Inria, CNRS, Grenoble INP, LIG --- Grenoble, France. Contact information: {\footnotesize \tt laercio.lima@inria.fr}} \thanks{This work was partially supported by the  Brazilian Federal Agency for the Support and Evaluation of Graduate Education (CAPES) and by the Brazilian Council of Technological and Scientific Development (CNPq), project grant 401266/2016-8.}}

\begin{document}



\maketitle
\thispagestyle{empty}
\pagestyle{empty}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\begin{abstract}

  Effectively mapping tasks of High Performance Computing (HPC) applications on parallel systems is crucial to assure substantial performance gains.
  As platforms and applications grow, load imbalance becomes a priority issue. 
  Even though centralized rescheduling has been a viable solution to mitigate this problem, its efficiency is not able to keep up with the increasing size of shared memory platforms.
  To efficiently solve load imbalance today, and in the years to come, we should prioritize decentralized strategies developed for large scale platforms.
  In this paper, we propose our \textit{Batch Task Migration} approach to improve decentralized global rescheduling, ultimately reducing communication costs and preserving task locality.
  We implemented and evaluated our approach in two different parallel platforms, using both synthetic workloads and a molecular dynamics (MD) benchmark. 
  Our solution was able to achieve speedups of up to 3.75 and 1.15 on rescheduling time, when compared to other centralized and distributed approaches, respectively. 
  Moreover, it improved the execution time of MD by factors up to 1.34 and 1.22 when compared to a scenario without load balancing on two different platforms.

\end{abstract}

\begin{keywords}
High Performance Computing, Global Rescheduling, Load Balancing, Performance Evaluation, Parallel Algorithms
\end{keywords}

\input{1-introduction.tex}
\input{2-relatedwork.tex}
\input{3-taskpack.tex}
\input{4-analysis.tex}
\input{5-implementation.tex}
\input{6-eval.tex}
\input{7-conclusion.tex}

\section*{ACKNOWLEDGEMENTS}
%\todo[inline]{@Laércio, adicionar agradecimentos no contexto do projeto de pesquisa ao CNPq? -- Acknowledgements são coisas para nos preocuparmos com o artigo aceito. Não vejo como algo necessário para o momento. }
%\todo[inline]{Adicionar agradecimentos para ambas as bolsas de mestrado}

The authors acknowledge the National Laboratory for Scientific Computing (LNCC/MCTI, Brazil) for providing HPC resources of the SDumont supercomputer, which have contributed to the research results reported within this paper (see \texttt{http://sdumont.lncc.br}).

Experiments presented in this paper were carried out using the Grid'5000 testbed, supported by a scientific interest group hosted by Inria and including CNRS, RENATER and several Universities as well as other organizations (see \texttt{https://www.grid5000.fr}).

\bibliographystyle{siam}
\bibliography{sample-bibliography}

\end{document}
