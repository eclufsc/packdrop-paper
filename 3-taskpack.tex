\section{Batch Task Migration Approach} \label{sec:algo}

%Global rescheduling algorithms must be effective in order to improve scheduling, but should also have low overhead in order to avoid reducing its benefits.
%To ensure a quick and informed remapping of tasks, we present the \textit{Task Packing Approach}.
%Sharing global information (e.g. processor affinity, estimated computational load, expected communication patterns, etc) allows a PE to create groups of the best tasks to leave a given processor and take the migration decision with one message, instead of several.

The role of the global rescheduler is to ultimately reduce the application makespan. 
Thus, the scheduler policy must incur low overheads as to not overshadow it's benefits. 
Moreover, we envision that a \textit{Batch Task Migration} approach can ensure a quick and informed remapping of tasks, ultimately reducing the amount of messages during the scheduling decision process. 
Therefore, this section is dedicated to present our \textit{PackDrop} strategy as a distributed refinement-based technique that implements our proposed \textit{Batch Task Migration} approach.

%In this work we present the \textit{PackDrop} strategy, a distributed refinement-based technique implementing our new approach. 
The main benefits we expect with our approach are: 
\begin{enumerate}
	\item \textit{Reducing} unnecessary communication;
	\item \textit{Exploring locality} of tasks mapped to the same PE, since migrations are done in groups;
	\item An \textit{accelerated decision making process}, consequence of the first;
	\item And a diminished total application runtime.
\end{enumerate}

First we will explain the \textit{Batch Assembly} (Algorithm~\ref{alg::packcreation}) and the \textit{Batch Sending} (Algorithm~\ref{alg::packsend}) processes of this strategy.
Then the complete strategy will be presented in Algorithm~\ref{algo:packdrop}, $PackDrop$.

For simplicity, in all algorithms presented here: i) the symbol:~``$\rightarrow$'' will represent a remote procedure call; ii) and the symbol:~``$\Rightarrow$'' will  represent the start of a reduction process.

\subsection{Batch Assembly} \label{sec:algo:creation}

The \textit{Batch Assembly} process for the \textit{PackDrop} strategy is presented in Algorithm~\ref{alg::packcreation}.
It uses an estimated batch size ($s$), a set of local tasks ($T$), the current PE $load$ and a threshold for PE loads ($thrs$), to create a set of leaving tasks ($LT$).
The threshold is used to calculate an upper bound ($ub$) of the average system load ($\overline{load}$), using Equation~\ref{eq:ceil}. 
The load of any set of tasks is given by Equation~\ref{eq:load}.

\begin{equation}
	ceil(l,v) = (1+v)\times l
    \label{eq:ceil}
\end{equation}

\begin{equation}
	load_{set}(B) = \sum_{t \in B}t\ \ |\ \ B \text{ is a set of tasks}
	\label{eq:load}
\end{equation}

With this information, each PE will take the task with the lower load within its pool, and pack it (lines~$3-6$).
Then, if the sum of all tasks in the pack is greater then the expected batch size ($s$), the batch is assembled and the strategy starts creating another one (lines~$7-10$).
The process is repeated while $ub$ is greater than $load$~(line~$2$).

\begin{algorithm}[!ht]
    \DontPrintSemicolon
    \KwIn{$s$; $  T$; $load$; $thrs$}
    \KwOut{$LT$}
    $L \gets \varnothing,\ LT \gets \varnothing,\ ub \gets ceil(\overline{load},thrs)$ \\
    \While{$load > ub$}{
        $t \gets a \in   T\ |\ a$ is the lower bound of $T$\\
        $  T \gets   T\ \backslash\ \{t\} $\\
        $\textit{L} \gets L\ \cup\ \{t\}$\\
        $load \gets load - t$\\
        \If{$load_{set}(L) > s$}{
            $LT \gets LT\ \cup\ L$\\
            $L \gets \varnothing $
        }
    }
    $LT \gets LT\ \cup\ L$   
    \caption{Batch Assembly} 
    \label{alg::packcreation}
\end{algorithm}

Any unfinished $LT$s should be sent even if those are not complete.
This is done to avoid having an overloaded PE that can still migrate tasks.
A PE that receives this load will not receive as much load as others, but since the PE will not overload, it should not be prejudicial.

\subsection{Batch Sending} \label{sec:algo:sending}

The \textit{Batch Sending} process is presented in Algorithm~\ref{alg::packsend}.
The algorithm will use the $LT$s, produced by \textit{Batch Assembly}, and the set of $Targets$, produced by an information propagation step ($Gossip$~\cite{gossip}), in order to schedule packs on remote PEs.
This will produce a set of expected Batch/Target ($BG$) pairs, which should be confirmed by the remote target.

While the local PE still has available $LT$s to send (line~$2$), it will choose a random target ($G$) for it (line~$4$) and invoke a remote $Send$ procedure on its target ($g$) (line~$5$).
The selected set of leaving tasks ($b$) will be removed from the $LT$ set (line~$6$) and paired up with its target on the $BG$ set~(line~$7$), waiting for confirmation.
This process is repeated until all elements in $LT$ have attempted a $Send$.

\begin{algorithm}[!ht]
    \DontPrintSemicolon
    \KwIn{$LT$, $G$}
    \KwOut{$BG$}
    $BG \gets \varnothing$ \\
    \While{$LT \neq \varnothing$}{
        $b\ \gets p\ |\ p\ \in\ LT$\\
        $g\ \gets  rand(G)$\\
        $Send(b)\rightarrow g$\\
        $LT\ \gets\ LT\ \backslash\ \{b\}$\\
        $\textit{BG} \gets BG\ \cup\ \{(b,\ g)\}$\\
    }  
    \caption{Batch Sending}  
    \label{alg::packsend}
\end{algorithm}

When $Sends$ receive a negative response, Algorithm~\ref{alg::packsend} can be refed with the failed attempts and initiate another round of sends, until every member of $LT$ is migrated.

\subsection{PackDrop Algorithm} \label{sec:algo:main}

The PackDrop strategy is presented in Algorithm~\ref{algo:packdrop}.
For the sake of simplicity, in the explanation of this algorithm \textit{packs} will be a short for ``set of leaving tasks" (seen in Sections~\ref{sec:algo:creation}~and~\ref{sec:algo:sending}).

It will run individually on each PE, in a distributed fashion. 
Using a current local mapping of tasks to PEs ($M$), local load ($load_{local}$), a local PE identification ($MyId$) and knowing all PEs within the system ($P$), to produce a new mapping ($M'$).
The mapping of tasks is defined by Equation~\ref{eq:taskmap} as a set of pairs ($task, PE$), describing the location of tasks.
A local map of tasks contains only tasks that are assigned to the current PE.

\begin{equation}
	M:\ T \rightarrow P
	\label{eq:taskmap}
\end{equation}

The first part of the algorithm (lines $1-6$) is the information sharing and setup process. 
This process is done through $2$ global reductions of average PE load (line~$2$) and global number of tasks (line~$3$).
In this implementation we used two constants: $0.05$, in order to limit the imbalance at $5\%$ (on line~$5$), and $2$, in order to regulate the size of packs (on line~$6$).

After setup PEs are divided between two different workflows (line~$7$).
At this time, \textit{overloaded} PEs will start the Batch Creation process (line~$8$), further explained in Algorithm~\ref{alg::packcreation}.
Meanwhile, \textit{underloaded} PEs will initiate a \textit{Gossip Protocol}~\cite{gossip} in order to inform other elements they are willing to receive work (line~$11$).
\textit{Gossip} is a well known epidemic algorithm used to spread information on a system, providing fast convergence and almost-global awareness of what was shared.

After the information propagation, each PE must synchronize to start the remap (line~$13$). 
At this point, the remapping process will begin.
PEs will send their packs using Algorithm~\ref{alg::packsend}, \textit{Batch Send}, asynchronously (line~$14$).
After a pack is sent, a PE will accept or reject it based on their current load, this is done via \textit{three-way handshake}, so both parts confirm the migration.

If one or more packs were not successfully exchanged, an \textit{overloaded} PE must attempt a new \textit{Batch Send}, in order to achieve load balance, as specified in Algorithm~\ref{alg::packsend}.
Once the PEs know their new mappings, tasks are migrated and the strategy is finished (line~$15$). 

\begin{algorithm}
	\DontPrintSemicolon
    \KwIn{$M$, $load_{local}$, $P$, $MyId$}
    \KwOut{$  M'$}
    $  M' \gets \varnothing$\\
    $al \gets (AveragePeLoadReduction(load_{local})\Rightarrow  P)$ \\
    $tc \gets (TotalTaskCountReduction(| M|)\Rightarrow  P)$\\
    //Average~task~size~\quad//5\%~precision~on~balance\qquad
    $ats\gets \frac{al}{tc}$ \qquad\qquad\  $thrs \gets 0.05$\\
    $ub \gets ceil(al,thrs)$ \qquad //Upper migration threshold\\
    $s \gets ats\times (2-\frac{|  P|}{tc}$) \qquad\qquad //Pack load\\
    \uIf{$l > ub$}{
    	$packs \gets BatchCreation(ps,  T(  M),l,thrs)$
    }
    \Else{
    	$packs \gets \varnothing$\\
    	$T \gets (Gossip \rightarrow  P)$ \qquad //Targets for migration\\
    }
    $---Synchronization Barrier---$\\
    //Requests are processed as they are received back
    $R \gets BatchSend(packs, T)$\\
    $TaskMap(R,   M, MyId)$
    \caption{PackDrop}
    \label{algo:packdrop}    
\end{algorithm}

\textit{PackDrop} intends to remap tasks to PEs in a distributed, workload-aware fashion.
This approach is the basis for new batch task migration distributed strategies that may take other factors into account.

