\section{Batch Task Migration Approach} \label{sec:algo}

%Global rescheduling algorithms must be effective in order to improve scheduling, but should also have low overhead in order to avoid reducing its benefits.
%To ensure a quick and informed remapping of tasks, we present the \textit{Task Packing Approach}.
%Sharing global information (e.g. processor affinity, estimated computational load, expected communication patterns, etc) allows a PE to create groups of the best tasks to leave a given processor and take the migration decision with one message, instead of several.

%\todo[inline]{Mesmo tendo falado que o algoritmo é distribuido, vale a pena ressaltar que os algoritmos apresentados executam um por PE. Done: Linha 25}

The role of the global rescheduler is to ultimately reduce the application makespan. 
Thus, the scheduler policy must incur low overheads as to not overshadow its benefits. 
Moreover, we envision that a \textit{Batch Task Migration} approach can ensure a quick and informed remapping of tasks, ultimately reducing the amount of messages during the scheduling decision process. 
Therefore, this section is dedicated to present our \textit{PackDrop} strategy as a distributed refinement-based technique that implements our proposed \textit{Batch Task Migration} approach.

%In this work we present the \textit{PackDrop} strategy, a distributed refinement-based technique implementing our new approach. 
The main benefits we expect with our approach are: 
\begin{enumerate}
	\item \textit{Reducing} unnecessary communication;
	\item \textit{Exploring locality} of tasks mapped to the same PE, since migrations are done in groups;
	\item An \textit{accelerated decision making process}, consequence of the first;
	\item And a diminished total application runtime.
\end{enumerate}

First we will explain the \textit{Batch Assembly} (Algorithm~\ref{alg::packcreation}) and the \textit{Batch Sending} (Algorithm~\ref{alg::packsend}) processes of this strategy.
Then the complete strategy will be presented in Algorithm~\ref{alg::packdrop}, $PackDrop$.
All presented algorithms execute individually on each PE and communicate via message passing.

For simplicity, in all algorithms presented here: i) the symbol:~``$\rightarrow$'' will represent a remote procedure call; ii) and the symbol:~``$\Rightarrow$'' will  represent the start of a reduction process.
Other symbols used in the algorithms may be found in Table~\ref{tab:algo:symbols}.

%\todo[inline]{Qual a lógica para a ordem na tabela? Aceito opiniões sobre como ordenar a tabela}

\begin{table}[t]
	\caption{List of symbols, variables and functions.}
	\begin{tabular}{l | l | l }
		Symbol & Meaning & Definition\\ \hline
		
		$v$				& Load threshold in \% 								& Equation~\ref{eq:ceil} \\
		$ub(load,v)$		& Upper bound of $l$ with threshold $v$		 		& Equation~\ref{eq:ceil} \\
		$load$			& Compute load of the local PE \\
		$load_{task}(t)$	& Compute load of a task $t$							& Equation~\ref{eq:load}	\\
		$load_{set}(T)$	& Load of a set ($T$) 								& Equation~\ref{eq:load} \\
		$T$				& Set of tasks 										& Equations~\ref{eq:load},~\ref{eq:taskmap} \\		
		$M$				& Mapping of tasks									& Equation~\ref{eq:taskmap} \\
		& &\\	

		$\rightarrow$ 	& Remote procedure call 								& Section~\ref{sec:algo} \\
		$\Rightarrow$ 	& Reduction process 									& Section~\ref{sec:algo} \\
		$load_{avg}$		& Average system load of a PE 						& Section~\ref{sec:algo:creation}\\ 
		$s$			  	& Compute load in a batch of tasks 					& Section~\ref{sec:algo:creation} \\
		$rand(S)$		& Random element of $S$ 								& Section~\ref{sec:algo:sending} \\
		$P$				& Global set of PEs 									& Section~\ref{sec:algo:main} \\
		$Gossip$			& Start of information propagation					& Section~\ref{sec:algo:main} \\		
		$pack$			& Set of leaving tasks								& Section~\ref{sec:algo:main} \\
		& &\\
				
		$LT$				& Set of tasks leaving a PE 							& Algorithm~\ref{alg::packcreation} \\
		$L$				& Set of tasks, subset of $LT$						& Algorithm~\ref{alg::packcreation} \\
		$G$				& Target for task receiving							& Algorithm~\ref{alg::packsend} \\
		$BG$				& Pairs expecting migration ack						& Algorithm~\ref{alg::packsend} \\ 
		$Send(T)\rightarrow G $ & Send a set $T$ to target $G$				& Algorithm~\ref{alg::packsend} \\ 
		$Id_l$ 			& Local PE identifier								& Algorithm~\ref{alg::packdrop} \\
		$TaskMap$		& Call RTS to start migrations						& Algorithm~\ref{alg::packdrop} \\
		
	\end{tabular}
	\label{tab:algo:symbols}
\end{table}

\subsection{Batch Assembly} \label{sec:algo:creation}

The \textit{Batch Assembly} process is presented in Algorithm~\ref{alg::packcreation}.
It uses an estimated batch size ($s$), a set of local tasks ($T$), the current PE $load$ and a threshold for PE loads ($v$), to create a set of leaving tasks ($LT$).
The threshold is used to calculate an upper bound of the average system load ($load_{avg}$), using Equation~\ref{eq:ceil}. 
The load of any set of tasks is given by Equation~\ref{eq:load}.
\begin{equation}
	ub(load,v) = (1+v)\times load
    \label{eq:ceil}
\end{equation}
\begin{equation}
	load_{set}(T) = \sum_{t \in T}{load_{task}(t)}\ \ |\ \ T \text{ is a set of tasks}
	\label{eq:load}
\end{equation}

With this information, each PE will take the task with the smallest load within its pool, and add it to a set of tasks ($L$) (lines~$3-5$).
Then, if the sum of all tasks in the pack is greater than the expected batch size ($s$), the batch is assembled and the strategy starts creating another one (lines~$6-9$).
The process is repeated while the set load is greater than the upper bound~(line~$2$).

Any unfinished $LT$s should be sent even if those are not complete.
This is done to avoid having an overloaded PE that can still migrate tasks.
A PE that receives this load will not receive as much load as others, but since the PE will not overload, it should not be prejudicial to global system balance.

\begin{algorithm}[!ht]
    \DontPrintSemicolon
    \KwIn{$s$, expected load of a batch; $T$, set of local tasks; $load_{avg}$, average global PE load; $v$, imbalance tolerance ratio}
    \KwOut{$LT$, set of tasks leaving this PE}
    $L \gets \varnothing,\ LT \gets \varnothing$ \\
    \While{$load_{set}(T) > ub(load_{avg},v)$}{
        $t \gets a \in   T\ |\ a$ is the lower bound of $T$\\
        $  T \gets   T\ \backslash\ \{t\} $\\
        $\textit{L} \gets L\ \cup\ \{t\}$\\
        %$load \gets load - t$\\
        \If{$load_{set}(L) > s$}{
            $LT \gets LT\ \cup\ L$\\
            $L \gets \varnothing $
        }
    }
    $LT \gets LT\ \cup\ L$   
    \caption{Batch Assembly} 
    \label{alg::packcreation}
\end{algorithm}
\vspace{-20pt}

\subsection{Batch Sending} \label{sec:algo:sending}

The \textit{Batch Sending} process is presented in Algorithm~\ref{alg::packsend}.
The algorithm will use the $LT$s, produced by \textit{Batch Assembly}, and the set of $Targets$, produced by an information propagation step ($Gossip$~\cite{gossip}), in order to schedule packs on remote PEs.
This will produce a set of expected Batch/Target ($BG$) pairs, which should be confirmed by the remote target.

For each subset $b \subset LT$ (as assigned in Algorithm~\ref{alg::packcreation}), the algorithm will select a random target from $G$~(line~$3$).
It will invoke a remote $Send$ procedure on the target $g$~(line~$4$), and register its attempt in a pair ($b$, $g$).
This pair is then stored in the expecting confirmation set ($BG$) (line~$5$).

\begin{algorithm}[!hb]
    \DontPrintSemicolon
    \KwIn{$LT$, set of tasks leaving the local PE; $G$, set of possible migration targets}
    \KwOut{$BG$, set of expected migrations}
    $BG \gets \varnothing$ \\
    \ForEach{$b \subset LT$}{
        %$b\ \gets p\ |\ p\ \in\ LT$\\
        $g\ \gets  rand(G)$\\
        $Send(b)\rightarrow g$\\
        %$LT\ \gets\ LT\ \backslash\ \{b\}$\\
        $\textit{BG} \gets BG\ \cup\ \{(b,\ g)\}$\\
    }  
    \caption{Batch Sending}  
    \label{alg::packsend}
\end{algorithm}

When $Sends$ receive a negative response, Algorithm~\ref{alg::packsend} may initiate another round of sends with the failed attempts so every member of $LT$ is migrated.

\subsection{PackDrop Algorithm} \label{sec:algo:main}

The \textit{PackDrop} strategy is presented in Algorithm~\ref{alg::packdrop}.
For simplicity, in the explanation of this algorithm \textit{packs} will be a short for ``set of leaving tasks" (seen in Sections~\ref{sec:algo:creation}~and~\ref{sec:algo:sending}).

\textit{PackDrop} will run individually on each PE, in a distributed fashion. 
Using a current local mapping of tasks to PEs ($M$), local load ($load$), a local PE identification ($Id_l$) and knowing all PEs within the system ($P$), to produce a new mapping ($M'$).
The mapping of tasks is defined by Equation~\ref{eq:taskmap} as a set of pairs ($task, PE$), describing the location of tasks.
A local mapping of tasks contains only tasks that are assigned to the current PE.
\begin{equation}
	M:\ T \rightarrow P
	\label{eq:taskmap}
\end{equation}

The first part of the algorithm (lines $1-6$) is the information sharing and setup process. 
This process is done through $2$ global reductions of average PE load (line~$2$) and global number of tasks (line~$3$).
In this implementation we used two constants: $0.05$, in order to limit the imbalance at $5\%$ (on line~$5$), and $2$, in order to regulate the size of packs (on line~$6$).

After setup PEs are divided between two different workflows (line~$7$).
At this time, \textit{overloaded} PEs will start the Batch Assembly procedure (line~$8$), previously explained in Algorithm~\ref{alg::packcreation}.
Meanwhile, \textit{underloaded} PEs will initiate a \textit{Gossip Protocol}~\cite{gossip} in order to inform other elements they are willing to receive work (line~$11$).
\textit{Gossip} is a well known epidemic algorithm used to spread messages on a system, providing fast convergence and near-global awareness of shared information.

Once information propagation is done, each PE must synchronize to start the remap (line~$13$). 
At this point, the remapping process will begin.
PEs will send their packs using Algorithm~\ref{alg::packsend}, \textit{Batch Send}, asynchronously (line~$14$).
After a pack is sent, PEs will accept or reject it based on their current load, this is done via \textit{three-way handshake}, so both parts confirm the migration.

If one or more packs were not successfully exchanged, an \textit{overloaded} PE must attempt a new \textit{Batch Send}, in order to achieve load balance, as specified in Section~\ref{sec:algo:sending}.
Once the PEs know their new mappings, tasks are migrated and the strategy is finished, requesting the confirmed migrations to the RTS (line~$15$). 
The $TaskMap$ function will take care of informing on the new mapping ($M'$) all tasks received via $Send$ and removed via $BatchSend$.

\textit{PackDrop} intends to remap tasks to PEs in a distributed, workload-aware fashion.
This approach is the basis for new batch task migration distributed strategies that may take other factors into account.

\begin{algorithm}[t]
	\DontPrintSemicolon
    \KwIn{$M$, local mapping of tasks; $load$, local PE load; $P$, set of all PEs in the system; $Id_{l}$, local PE identifier}
    \KwOut{$  M'$, new mapping of local tasks}
    $  M' \gets \varnothing$\\
    $load_{avg} \gets (AveragePeLoadReduction(load)\Rightarrow  P)$ \\
    $ttc \gets (TotalTaskCountReduction(|M|)\Rightarrow  P)$\\
    $ats\gets \frac{load_{avg}}{ttc}$ \qquad\qquad\qquad \tcp{{\small Average~task~size}}
    $v \gets 0.05$ \qquad \qquad \tcp{{\small 5\%~precision~on~balance}}
    $s \gets ats\times (2-\frac{|  P|}{ttc}$) \qquad\qquad\qquad\qquad \tcp{{\small Pack load}}
    \uIf{$load > ub(load_{avg},v)$}{
    	$packs \gets BatchCreation(ps,  T(M),load,v)$
    }
    \Else{
    	$packs \gets \varnothing$\\
    	$G \gets (Gossip \rightarrow  P)$ \tcp{{\small Targets for migration}}
    }
    $---Synchronization Barrier---$\\
    \tcc{{\small Requests are processed as they are received back}}
    $R \gets BatchSend(packs, G)$\\
    \tcp{{\small Implicit synchronization for TaskMap}}
    $TaskMap(R,M, M',Id_{l})$
    \caption{PackDrop}
    \label{alg::packdrop}    
\end{algorithm}