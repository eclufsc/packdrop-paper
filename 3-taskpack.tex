\section{Batch Task Migration Approach} \label{sec:algo}

%Global rescheduling algorithms must be effective in order to improve scheduling, but should also have low overhead in order to avoid reducing its benefits.
%To ensure a quick and informed remapping of tasks, we present the \textit{Task Packing Approach}.
%Sharing global information (e.g. processor affinity, estimated computational load, expected communication patterns, etc) allows a PE to create groups of the best tasks to leave a given processor and take the migration decision with one message, instead of several.

%\todo[inline]{Mesmo tendo falado que o algoritmo é distribuido, vale a pena ressaltar que os algoritmos apresentados executam um por PE. Done: Linha 25}

The role of the global rescheduler is to ultimately reduce the application makespan. 
Thus, the scheduler policy must incur low overheads as to not overshadow its benefits. 
Moreover, we envision that a \textit{Batch Task Migration} approach can ensure a quick and informed remapping of tasks, basically reducing the amount of messages during the scheduling decision process. 
Therefore, this section is dedicated to present our \packdrop strategy as a distributed refinement-based technique that implements our proposed \textit{Batch Task Migration} approach.

%In this work we present the \textit{PackDrop} strategy, a distributed refinement-based technique implementing our new approach. 
Overall, our approach intends to:

\begin{enumerate}
	\item \textit{Reduce unnecessary communication} between PEs;
	\item \textit{Exploit locality} among tasks in the same PE through grouped migrations;
	\item \textit{Accelerate the decision making process};
	\item \textit{Reduce the application makespan}.
\end{enumerate}

We will first explain two algorithms that are used by \packdrop: \batchassembly (Algorithm~\ref{alg::packcreation}) and \batchsend (Algorithm~\ref{alg::packsend}).
Then, the complete strategy, called \packdrop, will be presented in Algorithm~\ref{alg::packdrop}.
The \packdrop algorithm will be executed on each PE and communicates with other remote \packdrop instances via message passing.
For clarity, all symbols used in the algorithms are listed in Table~\ref{tab:algo:symbols}.

%\todo[inline]{Qual a lógica para a ordem na tabela? Aceito opiniões sobre como ordenar a tabela}

\begin{table}[t]
	\centering
	\caption{List of symbols, variables and functions.}
	\resizebox{\columnwidth}{!}{
	\begin{tabular}{l l l}
		\toprule
		\textbf{Symbol} & \textbf{Meaning} & \textbf{Definition}\\ 
		\midrule
		$v$				& Load threshold in \% 								& Equation~\ref{eq:ceil} \\
		$ub(load,v)$		& Upper bound of $load$ with threshold $v$		 		& Equation~\ref{eq:ceil} \\
		$load$			& Compute load of the local PE \\
		$load_{task}(t)$	& Compute load of a task $t$							& Equation~\ref{eq:load}	\\
		$load_{set}(T)$	& Load of a set ($T$) 								& Equation~\ref{eq:load} \\
		$T$				& Set of tasks 										& Equation~\ref{eq:load} \\		
		$ps$				& Estimate number of tasks in a $LT$					& Equation~\ref{eq:ps} \\
		$ttc$			& Total number of tasks in the system				& Equation~\ref{eq:ps} \\
		& &\\	

		$\rightarrow$ 	& Remote procedure call 								& Section~\ref{sec:algo} \\
		$\Rightarrow$ 	& Reduction process 									& Section~\ref{sec:algo} \\
		$load_{avg}$		& Average system load of a PE 						& Section~\ref{sec:algo:creation}\\ 
		$rand(S)$		& Random element of $S$ 								& Section~\ref{sec:algo:sending} \\
		$M$				& Mapping of tasks									& Section~\ref{sec:algo:main} \\
		$P$				& Global set of PEs 									& Section~\ref{sec:algo:main} \\
		$Gossip$			& Start of information propagation					& Section~\ref{sec:algo:main} \\		
		$pack$			& Set of leaving tasks								& Section~\ref{sec:algo:main} \\
		& &\\
				
		$LT$				& List of sets of tasks leaving a PE					& Algorithm~\ref{alg::packcreation} \\
		$L$				& Set of tasks assemblying a batch, subset of $T$ 	& Algorithm~\ref{alg::packcreation} \\
		$s$			  	& Threshold of load in a batch of tasks 				& Algorithm~\ref{alg::packcreation} \\
		$G$				& Target for task receiving							& Algorithm~\ref{alg::packsend} \\
		$BG$				& Pairs expecting migration ack						& Algorithm~\ref{alg::packsend} \\ 
		$Send(T)\rightarrow G $ & Send a set $T$ to target $G$				& Algorithm~\ref{alg::packsend} \\ 
		$Id_l$ 			& Local PE identifier								& Algorithm~\ref{alg::packdrop} \\
		$TaskMap$		& Call runtime system to start migrations					& Algorithm~\ref{alg::packdrop} \\
		\bottomrule
	\end{tabular}
	}
	\label{tab:algo:symbols}
	\vspace{-10pt}
\end{table}

\subsection{\batchassembly Algorithm} \label{sec:algo:creation}

The \batchassembly algorithm is presented in Algorithm~\ref{alg::packcreation}.
It uses an estimated batch size ($s$), a set of local tasks ($T$), the current PE $load$ and a threshold for PE loads ($v$), to create a list of leaving packs ($LT$).
The threshold is used to calculate an upper bound of the average system load ($load_{avg}$), using Equation~\ref{eq:ceil}. 
The load of any set of tasks is given by Equation~\ref{eq:load}.

\begin{equation}
	ub(load,v) = (1+v)\times load
    \label{eq:ceil}
\end{equation}
\begin{equation}
	load_{set}(T) = \sum_{t \in T}{load_{task}(t)}\ \ |\ \ T \text{ is a set of tasks}
	\label{eq:load}
\end{equation}

With this information, each PE will take the task with the smallest load within its pool, and add it to a set of tasks ($L$) (lines~$3-5$).
Then, if the sum of all tasks in the pack ($L$) is greater than the expected batch size ($s$), the batch is assembled and the strategy starts creating another one (lines~$6-9$).
The process is repeated until the load of the set becomes greater than the upper bound~(line~$2$).

Any unfinished packs should be sent even if these are not complete.
This is done in order to prioritize migration from overloaded PEs, even if they cannot assemble a complete batch.
A PE that receives this load will not receive as much load as others, but since the PE will not overload, it should not be prejudicial to global system balance.
%It is important to note that every pack ($L$) structure is preserved after the insertion on $LT$, so every pack will have roughly the same load on the migration step.

\begin{algorithm}[b]
    \DontPrintSemicolon
    \KwIn{$s$, load threshold of a batch; $T$, set of local tasks; $load_{avg}$, average global PE load; $v$, imbalance tolerance ratio.}
    \KwOut{$LT$, list of packs leaving this PE.}
    $L \gets \varnothing,\ LT \gets \varnothing$ \\
    \While{$load_{set}(T) > ub(load_{avg},v)$}{
        $t \gets a \in   T\ |\ a$ is the lower bound of $T$\\
        $  T \gets   T\ \backslash\ \{t\} $\\
        $\textit{L} \gets L\ \cup\ \{t\}$\\
        %$load \gets load - t$\\
        \If{$load_{set}(L) > s$}{
            $LT \gets LT\ \cup\ \{L\}$\\
            $L \gets \varnothing $
        }
    }
    $LT \gets LT\ \cup\ \{L\}$   
    \caption{\batchassembly} 
    \label{alg::packcreation}
\end{algorithm}

\subsection{\batchsend Algorithm} \label{sec:algo:sending}

The \batchsend algorithm is presented in Algorithm~\ref{alg::packsend}.
The algorithm will use the $LT$s, produced by \batchassembly, and the set of $Targets$, produced by an information propagation step ($Gossip$~\cite{gossip}), in order to schedule packs on remote PEs.
This will produce a set of expected Batch/Target ($BG$) pairs, which should be confirmed by the remote target.

For each subset $b \in LT$ (as assigned in Algorithm~\ref{alg::packcreation}), the algorithm will select a random target from $G$~(line~$3$).
It will invoke a remote $Send$ procedure on the target $g$~(line~$4$), and register its attempt in a pair ($b$, $g$).
This pair is then stored in the expecting confirmation set ($BG$) (line~$5$).

\begin{algorithm}[t]
    \DontPrintSemicolon
    \KwIn{$LT$, set of tasks leaving the local PE; $G$, set of possible migration targets.}
    \KwOut{$BG$, set of expected migrations.}
    $BG \gets \varnothing$ \\
    \ForEach{$b \in LT$}{
        %$b\ \gets p\ |\ p\ \in\ LT$\\
        $g\ \gets  rand(G)$\\
        $Send(b)\rightarrow g$\\
        %$LT\ \gets\ LT\ \backslash\ \{b\}$\\
        $\textit{BG} \gets BG\ \cup\ \{(b,\ g)\}$\\
    }  
    \caption{\batchsend}  
    \label{alg::packsend}
\end{algorithm}

In case of negative responses from remote $Send$ procedures, Algorithm~\ref{alg::packsend} may initiate another round of sends with the failed attempts so every member of $LT$ is migrated.

\subsection{\packdrop Algorithm} \label{sec:algo:main}

The \packdrop strategy is presented in Algorithm~\ref{alg::packdrop}.
For the sake of simplicity, \textit{packs} will be a short for ``set of leaving tasks" in this algorithm (recall Sections~\ref{sec:algo:creation}~and~\ref{sec:algo:sending}).

\packdrop will run individually on each PE, in a distributed fashion. 
It will produce a new mapping ($M'$) using a current local mapping of tasks to PEs ($M$), a local load ($load$), a local PE identification ($Id_l$) and the global set of PEs ($P$).
The mapping of tasks is defined as $M:\ T \rightarrow P$, which describes the relation of each task to its corresponding physical location.
A local mapping of tasks contains only tasks that are assigned to the current PE.

The first part of the algorithm (lines $1-6$) is the information sharing and setup process. 
This process is done through $2$ global reductions of average PE load (line~$2$) and global number of tasks (line~$3$).
In this implementation we used two constants: (i) $v$ is set to $0.05$ in order to limit the imbalance at $5\%$ (line~$5$); and (ii) in Equation~\ref{eq:ps}, a constant is set to $2$, in order to determine $ps$.

\begin{equation}
	ps = 2-\frac{|P|}{ttc}
	\label{eq:ps}
\end{equation}

This configuration aims to both increase communication efficiency (later explained in Section~\ref{sec:analysis}) and ensure precise balancing.
Finally, as $ps$ grows, so does the communication efficiency, but in order to do so, fine-grain migrations are compromised.
% We could add another sentence claming the application's dynamic nature would impact the fine-grain migrations anyway, but this paragraph is already waaaaaay too long.

Next, PEs are divided between two different workflows (line~$7$).
At this time, \textit{overloaded} PEs will start the \batchassembly algorithm (line~$8$), which was previously explained in Algorithm~\ref{alg::packcreation}.
Meanwhile, \textit{underloaded} PEs will initiate a \textit{Gossip Protocol}~\cite{gossip} in order to inform other elements they are willing to receive work (line~$11$).
\textit{Gossip} is a well-known epidemic algorithm used to spread messages on a system, providing fast convergence and near-global awareness of shared information.

Once information propagation is done, each PE must synchronize to start the remapping process (line~$13$). 
At this point, PEs will send their packs using \batchsend (Algorithm~\ref{alg::packsend}) asynchronously (line~$14$).
After a pack is sent, PEs will accept or reject it based on their current load. 
This is done via a \textit{three-way handshake}, so both parts confirm the migration.

\begin{algorithm}[t]
	\DontPrintSemicolon
    \KwIn{$M$, local mapping of tasks; $load$, local PE load; $P$, set of all PEs in the system; $Id_{l}$, local PE identifier.}
    \KwOut{$  M'$, new mapping of local tasks.}
    $  M' \gets \varnothing$\\
    $load_{avg} \gets (AveragePeLoadReduction(load)\Rightarrow  P)$ \\
    $ttc \gets (TotalTaskCountReduction(|M|)\Rightarrow  P)$\\
    $ats\gets \frac{load_{avg}}{ttc}$ \qquad\qquad\qquad \tcp{{\small Average~task~size}}
    $v \gets 0.05$ \qquad \qquad\ \tcp{{\small 5\%~precision~on~balance}}
    $s \gets ats\times ps$ \qquad\qquad\qquad\qquad\qquad \tcp{{\small Pack load}}
    \uIf{$load > ub(load_{avg},v)$}{
    	$packs \gets BatchAssembly(s,  T(M),load,v)$
    }
    \Else{
    	$packs \gets \varnothing$\\
    	$G \gets (Gossip \rightarrow  P)$ \tcp{{\small Targets for migration}}
    }
    $---Synchronization Barrier---$\\
    \tcc{{\small Requests are processed as they are received back}}
    $R \gets BatchSend(packs, G)$\\
    \tcp{{\small Implicit synchronization in TaskMap}}
    $TaskMap(R,M, M',Id_{l})$
    \caption{\packdrop}
    \label{alg::packdrop}    
\end{algorithm}

If one or more packs were not successfully exchanged, an \textit{overloaded} PE must attempt a new \batchsend, in order to achieve load balance, as specified in Section~\ref{sec:algo:sending}.
Once PEs know their new mappings, tasks are migrated and the strategy is finished, requesting the confirmed migrations to the underlying runtime system (RTS) on line~$15$. 
The $TaskMap$ function will take care of informing the new mapping ($M'$) to all tasks received via $Send$ and removed via \batchsend.

\packdrop intends to remap tasks to PEs in a distributed, workload-aware fashion.
This approach may be the basis for new batch task migration distributed strategies that might take other factors into account.