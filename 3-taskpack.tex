\section{Batch Task Migration Approach} \label{sec:algo}

%Global rescheduling algorithms must be effective in order to improve scheduling, but should also have low overhead in order to avoid reducing its benefits.
%To ensure a quick and informed remapping of tasks, we present the \textit{Task Packing Approach}.
%Sharing global information (e.g. processor affinity, estimated computational load, expected communication patterns, etc) allows a PE to create groups of the best tasks to leave a given processor and take the migration decision with one message, instead of several.

%\todo[inline]{Mesmo tendo falado que o algoritmo é distribuido, vale a pena ressaltar que os algoritmos apresentados executam um por PE. Done: Linha 25}

The role of the global rescheduler is to ultimately reduce the application makespan. 
Thus, the scheduler policy must incur low overheads as to not overshadow its benefits. 
Moreover, we envision that a \textit{Batch Task Migration} approach can ensure a quick and informed remapping of tasks, ultimately reducing the amount of messages during the scheduling decision process. 
Therefore, this section is dedicated to present our \packdrop strategy as a distributed refinement-based technique that implements our proposed \textit{Batch Task Migration} approach.

%In this work we present the \textit{PackDrop} strategy, a distributed refinement-based technique implementing our new approach. 
Overall, our approach intends to:

\begin{enumerate}
	\item \textit{Reduce unnecessary communication} between PEs;
	\item \textit{Exploit task locality} within PEs, since migrations are done in groups;
	\item \textit{Accelerate the decision making process}, consequence of the first; and
	\item \textit{Reduce the application makespan}.
\end{enumerate}

We first explain two algorithms that are used by \packdrop: \batchassembly (Algorithm~\ref{alg::packcreation}) and \batchsend (Algorithm~\ref{alg::packsend}).
Then, the complete strategy, called \packdrop, will be presented in Algorithm~\ref{alg::packdrop}.
We assume that the \packdrop algorithm is executed on each PE and communicates with other remote \packdrop instances via message passing.
For clarity, all symbols used in the algorithms are listed in Table~\ref{tab:algo:symbols}.

%\todo[inline]{Qual a lógica para a ordem na tabela? Aceito opiniões sobre como ordenar a tabela}

\begin{table}[t]
	\centering
	\caption{List of symbols, variables and functions.}
	\resizebox{\columnwidth}{!}{
	\begin{tabular}{l l l}
		\toprule
		\textbf{Symbol} & \textbf{Meaning} & \textbf{Definition}\\ 
		\midrule
		$v$				& Load threshold in \% 								& Equation~\ref{eq:ceil} \\
		$ub(load,v)$		& Upper bound of $l$ with threshold $v$		 		& Equation~\ref{eq:ceil} \\
		$load$			& Compute load of the local PE \\
		$load_{task}(t)$	& Compute load of a task $t$							& Equation~\ref{eq:load}	\\
		$load_{set}(T)$	& Load of a set ($T$) 								& Equation~\ref{eq:load} \\
		$T$				& Set of tasks 										& Equations~\ref{eq:load},~\ref{eq:taskmap} \\		
		$M$				& Mapping of tasks									& Equation~\ref{eq:taskmap} \\
		& &\\	

		$\rightarrow$ 	& Remote procedure call 								& Section~\ref{sec:algo} \\
		$\Rightarrow$ 	& Reduction process 									& Section~\ref{sec:algo} \\
		$load_{avg}$		& Average system load of a PE 						& Section~\ref{sec:algo:creation}\\ 
		$s$			  	& Compute load in a batch of tasks 					& Section~\ref{sec:algo:creation} \\
		$rand(S)$		& Random element of $S$ 								& Section~\ref{sec:algo:sending} \\
		$P$				& Global set of PEs 									& Section~\ref{sec:algo:main} \\
		$Gossip$			& Start of information propagation					& Section~\ref{sec:algo:main} \\		
		$pack$			& Set of leaving tasks								& Section~\ref{sec:algo:main} \\
		& &\\
				
		$LT$				& Set of tasks leaving a PE 							& Algorithm~\ref{alg::packcreation} \\
		$L$				& Set of tasks, subset of $LT$						& Algorithm~\ref{alg::packcreation} \\
		$G$				& Target for task receiving							& Algorithm~\ref{alg::packsend} \\
		$BG$				& Pairs expecting migration ack						& Algorithm~\ref{alg::packsend} \\ 
		$Send(T)\rightarrow G $ & Send a set $T$ to target $G$				& Algorithm~\ref{alg::packsend} \\ 
		$Id_l$ 			& Local PE identifier								& Algorithm~\ref{alg::packdrop} \\
		$TaskMap$		& Call runtime system to start migrations					& Algorithm~\ref{alg::packdrop} \\
		\bottomrule
	\end{tabular}
	}
	\label{tab:algo:symbols}
\end{table}

\subsection{\batchassembly Algorithm} \label{sec:algo:creation}

The \batchassembly algorithm is presented in Algorithm~\ref{alg::packcreation}.
It uses an estimated batch size ($s$), a set of local tasks ($T$), the current PE $load$ and a threshold for PE loads ($v$), to create a set of leaving tasks ($LT$).
The threshold is used to calculate an upper bound of the average system load ($load_{avg}$), using Equation~\ref{eq:ceil}. 
The load of any set of tasks is given by Equation~\ref{eq:load}.

\begin{equation}
	ub(load,v) = (1+v)\times load
    \label{eq:ceil}
\end{equation}
\begin{equation}
	load_{set}(T) = \sum_{t \in T}{load_{task}(t)}\ \ |\ \ T \text{ is a set of tasks}
	\label{eq:load}
\end{equation}

With this information, each PE will take the task with the smallest load within its pool, and add it to a set of tasks ($L$) (lines~$3-5$).
Then, if the sum of all tasks in the pack is greater than the expected batch size ($s$), the batch is assembled and the strategy starts creating another one (lines~$6-9$).
The process is repeated until the load of the set becomes greater than the upper bound~(line~$2$).

Any unfinished $LT$s should be sent even if those are not complete.
This is done to avoid having an overloaded PE that can still migrate tasks.
A PE that receives this load will not receive as much load as others, but since the PE will not overload, it should not be prejudicial to global system balance.

\begin{algorithm}[b]
    \DontPrintSemicolon
    \KwIn{$s$, expected load of a batch; $T$, set of local tasks; $load_{avg}$, average global PE load; $v$, imbalance tolerance ratio.}
    \KwOut{$LT$, set of tasks leaving this PE.}
    $L \gets \varnothing,\ LT \gets \varnothing$ \\
    \While{$load_{set}(T) > ub(load_{avg},v)$}{
        $t \gets a \in   T\ |\ a$ is the lower bound of $T$\\
        $  T \gets   T\ \backslash\ \{t\} $\\
        $\textit{L} \gets L\ \cup\ \{t\}$\\
        %$load \gets load - t$\\
        \If{$load_{set}(L) > s$}{
            $LT \gets LT\ \cup\ L$\\
            $L \gets \varnothing $
        }
    }
    $LT \gets LT\ \cup\ L$   
    \caption{\batchassembly} 
    \label{alg::packcreation}
\end{algorithm}

\subsection{\batchsend Algorithm} \label{sec:algo:sending}

The \batchsend algorithm is presented in Algorithm~\ref{alg::packsend}.
The algorithm will use the $LT$s, produced by \batchassembly, and the set of $Targets$, produced by an information propagation step ($Gossip$~\cite{gossip}), in order to schedule packs on remote PEs.
This will produce a set of expected Batch/Target ($BG$) pairs, which should be confirmed by the remote target.

For each subset $b \subset LT$ (as assigned in Algorithm~\ref{alg::packcreation}), the algorithm will select a random target from $G$~(line~$3$).
It will invoke a remote $Send$ procedure on the target $g$~(line~$4$), and register its attempt in a pair ($b$, $g$).
This pair is then stored in the expecting confirmation set ($BG$) (line~$5$).

\begin{algorithm}[t]
    \DontPrintSemicolon
    \KwIn{$LT$, set of tasks leaving the local PE; $G$, set of possible migration targets.}
    \KwOut{$BG$, set of expected migrations.}
    $BG \gets \varnothing$ \\
    \ForEach{$b \subset LT$}{
        %$b\ \gets p\ |\ p\ \in\ LT$\\
        $g\ \gets  rand(G)$\\
        $Send(b)\rightarrow g$\\
        %$LT\ \gets\ LT\ \backslash\ \{b\}$\\
        $\textit{BG} \gets BG\ \cup\ \{(b,\ g)\}$\\
    }  
    \caption{\batchsend}  
    \label{alg::packsend}
\end{algorithm}

In case of negative responses from remote $Send$ procedures, Algorithm~\ref{alg::packsend} may initiate another round of sends with the failed attempts so every member of $LT$ is migrated.

\subsection{\packdrop Algorithm} \label{sec:algo:main}

The \packdrop strategy is presented in Algorithm~\ref{alg::packdrop}.
For simplicity, in the explanation of this algorithm \textit{packs} will be a short for ``set of leaving tasks" (seen in Sections~\ref{sec:algo:creation}~and~\ref{sec:algo:sending}).

\packdrop will run individually on each PE, in a distributed fashion. 
It will produce a new mapping ($M'$) using a current local mapping of tasks to PEs ($M$), local load ($load$), a local PE identification ($Id_l$) and the global set of PEs ($P$).
The mapping of tasks is defined by Equation~\ref{eq:taskmap} as a set of pairs ($task, PE$), which describe the location of tasks.
A local mapping of tasks contains only tasks that are assigned to the current PE.

\begin{equation}
	M:\ T \rightarrow P
	\label{eq:taskmap}
\end{equation}

The first part of the algorithm (lines $1-6$) is the information sharing and setup process. 
This process is done through $2$ global reductions of average PE load (line~$2$) and global number of tasks (line~$3$).
\tofix{
	In this implementation we used two constants. The first one ($v$) was set to $0.05$ in order to limit the imbalance at $5\%$ (line~$5$).
	The second one was defined in $ps$ and set to $2$ in order to regulate the size of packs (line~$6$).
	The value of $ps$ is defined by Equation~\ref{eq:ps}. The rationale behind this is... COMPLETE THE SENTENCE.
}

\begin{equation}
	ps = 2-\frac{|P|}{ttc}
	\label{eq:ps}
\end{equation}

Next, PEs are divided between two different workflows (line~$7$).
At this time, \textit{overloaded} PEs will start the \batchassembly algorithm (line~$8$), which was previously explained in Algorithm~\ref{alg::packcreation}.
Meanwhile, \textit{underloaded} PEs will initiate a \textit{Gossip Protocol}~\cite{gossip} in order to inform other elements they are willing to receive work (line~$11$).
\textit{Gossip} is a well-known epidemic algorithm used to spread messages on a system, providing fast convergence and near-global awareness of shared information.

Once information propagation is done, each PE must synchronize to start the remapping process (line~$13$). 
At this point, PEs will send their packs using \batchsend (Algorithm~\ref{alg::packsend}) asynchronously (line~$14$).
After a pack is sent, PEs will accept or reject it based on their current load, this is done via \textit{three-way handshake}, so both parts confirm the migration.

\begin{algorithm}[t]
	\DontPrintSemicolon
    \KwIn{$M$, local mapping of tasks; $load$, local PE load; $P$, set of all PEs in the system; $Id_{l}$, local PE identifier.}
    \KwOut{$  M'$, new mapping of local tasks.}
    $  M' \gets \varnothing$\\
    $load_{avg} \gets (AveragePeLoadReduction(load)\Rightarrow  P)$ \\
    $ttc \gets (TotalTaskCountReduction(|M|)\Rightarrow  P)$\\
    $ats\gets \frac{load_{avg}}{ttc}$ \qquad\qquad\qquad \tcp{{\small Average~task~size}}
    $v \gets 0.05$ \qquad \qquad\ \tcp{{\small 5\%~precision~on~balance}}
    $s \gets ats\times ps$ \qquad\qquad\qquad\qquad\qquad \tcp{{\small Pack load}}
    \uIf{$load > ub(load_{avg},v)$}{
    	$packs \gets BatchAssembly(s,  T(M),load,v)$
    }
    \Else{
    	$packs \gets \varnothing$\\
    	$G \gets (Gossip \rightarrow  P)$ \tcp{{\small Targets for migration}}
    }
    $---Synchronization Barrier---$\\
    \tcc{{\small Requests are processed as they are received back}}
    $R \gets BatchSend(packs, G)$\\
    \tcp{{\small Implicit synchronization in TaskMap}}
    $TaskMap(R,M, M',Id_{l})$
    \caption{\packdrop}
    \label{alg::packdrop}    
\end{algorithm}

If one or more packs were not successfully exchanged, an \textit{overloaded} PE must attempt a new \batchsend, in order to achieve load balance, as specified in Section~\ref{sec:algo:sending}.
Once the PEs know their new mappings, tasks are migrated and the strategy is finished, requesting the confirmed migrations to the RTS (line~$15$). 
The $TaskMap$ function will take care of informing the new mapping ($M'$) to all tasks received via $Send$ and removed via \batchsend.

\packdrop intends to remap tasks to PEs in a distributed, workload-aware fashion.
This approach is the basis for new batch task migration distributed strategies that may take other factors into account.

