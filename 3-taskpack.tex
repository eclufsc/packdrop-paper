\section{The Task Packing Approach}

Global rescheduling algorithms must be effective in order to improve scheduling, but should also have low overhead in order to avoid reducing its benefits.
To ensure a quick and informed remapping of tasks, we present the \textit{Task Packing Approach}.
Sharing global information (e.g. processor affinity, estimated computational load, expected communication patterns, etc) allows a PE to create groups of the best tasks to leave a given processor and take the migration decision with one message, instead of several.

In this work we present the \textit{PackDrop} strategy, a distributed refinement-based technique implementing our new approach. % Saying that it is similar to Grapevine here is not helping to sell the strategy
We expect that: i) reducing unnecessary communication; ii) exploring locality of tasks mapped to the same PE, since migrations are done in groups; thus iii) resulting in an accelerated decision making process, which should bring a better overall runtime for applications. % enumerate expected benefits to highlight them

First we will explain the \textit{Pack Creation} (Algorithm~\ref{alg::packcreation}) and the \textit{Pack Sending} (Algorithm~\ref{alg::packsend}) processes of this strategy.
Then the complete strategy will be presented in Algorithm~\ref{algo:packdrop}, $PackDrop$.

For simplicity, in all algorithms presented here: i) the symbol:~``$\rightarrow$'' will represent a remote procedure call; ii) and the symbol:~``$\Rightarrow$'' will  represent the start of a reduction process.

\subsection{Pack Creation}

The \textit{Pack Creation} process for the \textit{PackDrop} strategy is presented in Algorithm~\ref{alg::packcreation}.
It uses an estimated pack size ($ps$), a set of local tasks ($T$), the current PE $load$ and a threshold for PE loads ($thrs$), to create a set of $Packs$.
The threshold is used to calculate an upper bound ($ub$) of the average system load ($\overline{load}$), using Equation~\ref{eq:ceil}. 

\begin{equation}
	ceil(l,v) = (1+v)\times l
    \label{eq:ceil}
\end{equation}

\begin{equation}
	load(B) = \sum_{t \in B}t\ \ |\ \ B \text{ is a bag of tasks}
	\label{eq:load}
\end{equation}

With this information, each PE will take the task with the lower load within its pool, and pack it (lines~$3-6$). % task have load, they are not loaded
Then, if the sum of all tasks in the pack is greater then the expected pack size ($ps$), the pack is closed and the strategy start filling another one (lines~$7-10$).
The process is repeated while $ub$ is greater than $load$~(line~$2$).

\begin{algorithm}[!ht]
    \DontPrintSemicolon
    \KwIn{$ps$; $  T$; $load$; $thrs$}
    \KwOut{$Packs$}
    $P \gets \varnothing,\ Packs \gets \varnothing,\ ub \gets ceil(\overline{load},thrs)$ \\
    \While{$load > ub$}{
        $t \gets a \in   T\ |\ a$ is the lower bound of $T$\\
        $  T \gets   T\ \backslash\ \{t\} $\\
        $\textit{P} \gets P\ \cup\ \{t\}$\\
        $load \gets load - t$\\
        \If{$load(P) > ps$}{
            $Packs \gets Packs\ \cup\ P$\\
            $P \gets \varnothing $
        }
    }
    $Packs \gets Packs\ \cup\ P$   
    \caption{Pack Creation} 
    \label{alg::packcreation}
\end{algorithm}

\subsection{Pack Sending}

The \textit{Pack Sending} process is presented in Algorithm~\ref{alg::packsend}.
The algorithm will use the set of $Packs$, produced by \textit{Pack Creation}, and the set of $\ Targets$, produced by an information propagation step ($Gossip$~\cite{gossip}), in order to schedule packs on remote PEs.
This will produce a set with expected $Pack/Target$ pairs, which should be confirmed by the remote target.

Basically, while the local PE still has available $Packs$ to send (line~$2$), it will choose a random $Target$ for it (line~$4$) and invoke a remote $Send$ procedure on its $target$ (line~$5$).
The selected $pack$ will be removed from the $Packs$ set (line~$6$) and paired up with its $target$ on the $R$ set~(line~$7$), waiting for confirmation.
This process is repeated until all elements in $Packs$ have attempted a $Send$.

\begin{algorithm}[!ht]
    \DontPrintSemicolon
    \KwIn{$Packs$, $Targets$}
    \KwOut{$R$}
    $R \gets \varnothing$ \\
    \While{$Packs \neq \varnothing$}{
        $pack\ \gets p\ |\ p\ \in\ Packs$\\
        $target\ \gets  rand(Targets)$\\
        $Send(pack)\rightarrow target$\\
        $Packs\ \gets\ Packs\ \backslash\ \{pack\}$\\
        $\textit{R} \gets R\ \cup\ \{(pack,\ target)\}$\\
    }  
    \caption{Pack Sending}  
    \label{alg::packsend}
\end{algorithm}

\subsection{The PackDrop Algorithm}

The PackDrop strategy is presented in Algorithm~\ref{algo:packdrop}. % What does it mean formally?
It will run individually on each PE, in a distributed fashion. 
Using a current local mapping of tasks to PEs ($  M$), local load ($l$) and knowing all PEs in the system ($  P$), to produce a new mapping ($  M'$).
The mapping of tasks is defined by Equation~\ref{eq:taskmap} as a set of pairs (task, PE), describing the location of tasks.
A local map of tasks contains only tasks that are assigned to the current PE.

\begin{equation}
	M:\ T \rightarrow P
	\label{eq:taskmap}
\end{equation}

In this implementation we used two constants: $1.05$, in order to limit the imbalance at $5\%$ (on line~$5$), and $2$, in order to regulate the size of packs (on line~$6$).

The first part of the algorithm (lines $1-6$) is the information sharing and setup process. 
This process is done through $2$ global reductions of average PE load (line~$2$) and global number of tasks (line~$3$).

Then (line~$7$) PEs are divided between two different workflows.
At this time, \textit{overloaded} PEs will start the Pack Creation process (line~$8$), further explained in Algorithm~\ref{alg::packcreation}.
Meanwhile, \textit{underloaded} PEs will start a \textit{Gossip Protocol}~\cite{gossip} in order to inform other elements they are willing to receive work (line~$11$).
\textit{Gossip} is a well known epidemic algorithm used to spread information on a system, providing fast convergence and almost-global awareness of what was shared.

Then, each PE must synchronize to start the remap (line~$13$). 
At this point, the remapping process will begin.
PEs will send their packs using Algorithm~\ref{alg::packsend}, \textit{Pack Send}, asynchronously (line~$14$).
After a pack is sent, a PE will accept or reject it based on their current load, this is done via \textit{three-way handshake}, so both parts confirm the migration.

If one or more packs were not successfully exchanged, an \textit{overloaded} PE must attempt a new \textit{Pack Send}, in order to achieve load balance.
Once the PEs know their new mappings, tasks are migrated and the strategy is finished (line~$15$). 

\begin{algorithm}
	\DontPrintSemicolon
    \KwIn{$  M$, $l$, $  P$}
    \KwOut{$  M'$}
    $  M' \gets \varnothing$\\
    $al \gets (AveragePeLoadReduction(l)\Rightarrow  P)$ \\
    $tc \gets (TotalTaskCountReduction(|  M|)\Rightarrow  P)$\\
    //Average~task~size~\quad//5\%~precision~on~balance\qquad
    $ats\gets \frac{al}{tc}$ \qquad\qquad $thrs \gets 0.05$\\
    $ub \gets ceil(al,thrs)$ \qquad //Upper migration threshold\\
    $ps \gets ats\times (2-\frac{|  P|}{tc}$) \qquad\qquad //Pack load\\
    \uIf{$l > ub$}{
    	$packs \gets PackCreation(ps,  T(  M),l,thrs)$
    }
    \Else{
    	$packs \gets \varnothing$\\
    	$T \gets (Gossip \rightarrow  P)$ \qquad //Targets for migration\\
    }
    $---Synchronization Barrier---$\\
    //Requests are processed as they are received back
    $R \gets PackSend(packs, T)$\\
    $TaskMap(R,   M, MyId)$
    \caption{PackDrop}
    \label{algo:packdrop}    
\end{algorithm}

\textit{PackDrop} intends to remap tasks to PEs in a distributed, workload-aware fashion.
This approach is the basis for new bin packing distributed strategies that may take other factors into account.
% Since it is similar to the centralized \textit{Refine} and to the distributed \textit{Grapevine} strategies, but using the \textbf{Task Packing Approach}, we intend to compare it to th.

