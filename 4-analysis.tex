\section{Analysis of the Algorithm}

This section presents an analysis of the Parallel Algorithm~\ref{algo:packdrop}~(PackDrop). 
The complexity of the information propagation ($Gossip$) has being evaluated as $O(log_fn)$~\cite{grapevine},
where $f$ is the fanout for the algorithm and $n$ is the number of PEs in the system.
Here we use $f=2$, in order to avoid network congestion. 

For the sake of simplicity, in the remainder of this analysis, the number of tasks in the system
will be referred to as $m$, and the costs for computation and communication will be represented as $p_c$ and $c_c$, respectively.
We also assume $c_c > p_c$ for all concurrent scenarios, since communication costs are several orders of magnitude higher than computational costs.
$C(f)$ is refered here as the total cost for a given function $f$.
Unmentioned lines are assumed to have non-varying cost, and thus will not interfere in the asymptotic analysis.

Lines~2~and~3 are global reductions, which have a well known cost of $O(log\ n)$.
Lines~8~and~11 are concurrent, so their cost will be the max among both:
\begin{equation}
  max(C(BatchCreation),C(Gossip))
\end{equation}
We also know that the worst case for $BatchCreation$ (Algorithm~\ref{alg::packcreation}) is rather unrealistic, 
since it would assume that a single PE contains $m$ tasks and a single task may have a load greater than the average system load, being $O(m-1)$, assuming $1$ would not be migrated, asymptotically, $O(m)$.

This takes lines~8~and~11 cost to:
\begin{equation}
 max(C(p_cm),C(c_clog_fn))
\end{equation}
and since $c_c$ is several orders of magnitude bigger than $p_c$, we could assume $C(BatchCreation)\in C(Gossip)$, which makes the 
complexity of these lines to $O(log_fn)$.

Finally, line 14 will have a complexity equal to the largest number of packs migrated by an overloaded PE.
Let $ps$ be the mean number of tasks inside of a pack, and $m_l$ the maximum number of tasks in a given overloaded PE.
At this step, a solution without Batch Task Migration would have a cost of $c_c\times m_l$, while our approach will divide this complexity by $ps$. 
This is the most expensive in Algorithm~\ref{algo:packdrop}, and as such it is the most interesting one to optimize.
Our final asymptotic complexity will be:
\begin{equation}
 C(PackDrop) = O(m_l/ps) + O(log\ n)
 \label{eq:worstcase}
\end{equation}

This shows that determining a good $s$ value is crucial to achieve the best performance with this algorithm.
Higher values of $s$ will lower communication complexity, but may lead to an imprecise scheduling.
In our Implementation, we chose a moderate value of $s$, of around $2$ average tasks, varying to smaller values according to system load.
This guarantees a precise scheduling, but still gives margin to have several small tasks migrating at once, saving communication costs.
